{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm, pyplot as plt\n",
    "from matplotlib.dates import YearLocator, MonthLocator\n",
    "import cPickle as pk\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import math\n",
    "\n",
    "def HMM_MAD(model,obs_levels):\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    abs_error = np.absolute(obs_levels - predict_levels)\n",
    "    return np.mean(abs_error)/np.mean(obs_levels)\n",
    "\n",
    "def perc_std_expl(model,obs_levels):\n",
    "    \"\"\"\n",
    "    :param observed: df of observed energy levels per channel\n",
    "    :param predicted: df of predicted energy levels per channel\n",
    "    :return: percentage of standard deviation explained\n",
    "    \"\"\"\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    obs_mean = np.mean(obs_levels)\n",
    "    r2 = 1 - (np.sum((obs_levels - predict_levels)**2))/np.sum((obs_levels - obs_mean)**2)\n",
    "    return 1 - math.sqrt(1-r2)\n",
    "\n",
    "def r2(model,obs_levels):\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    obs_mean = np.mean(obs_levels)\n",
    "    r2 = 1 - (np.sum((obs_levels - predict_levels)**2))/np.sum((obs_levels - obs_mean)**2)\n",
    "    return r2\n",
    "\n",
    "class HMM():\n",
    "    def __init__(self, X_test, X_train):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.n_states = None\n",
    "        self.model =  None\n",
    "\n",
    "    def fit_HMM(self,error_metric):\n",
    "        print \"Looking for optimal number of states and fitting HMM\"\n",
    "        for i in xrange(2,5):\n",
    "            candidate = GaussianHMM(n_components=i, covariance_type=\"full\", n_iter=1000)\n",
    "            candidate.fit(self.X_train)\n",
    "            if error_metric == HMM_MAD:\n",
    "                error = HMM_MAD(candidate,self.X_test)\n",
    "                if i == 2:\n",
    "                    best_guess = error\n",
    "                    best_model = candidate\n",
    "                    opt_n_states = i\n",
    "                else:\n",
    "                    if error < best_guess:\n",
    "                        opt_n_states = i\n",
    "                        best_model = candidate\n",
    "                        best_guess = error\n",
    "            else:\n",
    "                error = error_metric(candidate,self.X_test)\n",
    "                if i == 2:\n",
    "                    best_guess = error\n",
    "                    best_model = candidate\n",
    "                    opt_n_states = i\n",
    "                else:\n",
    "                    if error > best_guess:\n",
    "                        opt_n_states = i\n",
    "                        best_model = candidate\n",
    "                        best_guess = error\n",
    "        self.model = best_model\n",
    "        self.n_states = opt_n_states\n",
    "        print \"Done. Lowest error of {} achieved with {} states\".format(best_guess, opt_n_states)\n",
    "\n",
    "    def extract_means(self):\n",
    "        return self.model.means_[:,0].flatten()\n",
    "\n",
    "    def HMM_total_accuracy(self, obs_levels, state_means):\n",
    "        hidden_states = self.model.predict(obs_levels)\n",
    "        predict_levels = [state_means[state] for state in hidden_states]\n",
    "        test_error = 1 - (np.sum(obs_levels[:,0]) - np.sum(predict_levels))/np.sum(obs_levels[:,0])\n",
    "        return test_error\n",
    "\n",
    "    def HMM_MAD_perc(self,obs_levels, state_means):\n",
    "        hidden_states = self.model.predict(obs_levels)\n",
    "        predict_levels = np.array([state_means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "        abs_error = np.absolute(obs_levels - predict_levels)\n",
    "        return np.mean(abs_error)/np.mean(obs_levels)\n",
    "\n",
    "    def run(self):\n",
    "        self.fit_HMM()\n",
    "        state_means = self.extract_means()\n",
    "        test_error = self.HMM_accuracy(self.X_test, state_means)\n",
    "        print \"Accuracy for the model with {} hidden states is: {}\".format(self.n_states,test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from Preprocessing import cluster\n",
    "\n",
    "def compute_A_fhmm(list_A):\n",
    "    result = list_A[0]\n",
    "    for i in range(len(list_A) - 1):\n",
    "        result = np.kron(result, list_A[i + 1])\n",
    "    return result\n",
    "\n",
    "def combine_parameters(ind_parameters_list):\n",
    "    '''\n",
    "    Function to compute factorized HMM parameters such as starting probabilities or transition matrices\n",
    "    from individual model parameters\n",
    "    :param ind_parameters_list: parameter list for individual models (per appliance), e.g. list of starting probabilites,\n",
    "    transition matrices\n",
    "    :return: matrix of factorized model parameters\n",
    "    '''\n",
    "    FactAParam = ind_parameters_list[0]\n",
    "    for idx in xrange(1,len(ind_parameters_list)):\n",
    "        FactA = np.kron(FactAParam,ind_parameters_list[idx])\n",
    "    return FactAParam\n",
    "\n",
    "def compute_pi_fhmm(list_pi):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    list_pi : List of PI's of individual learnt HMMs\n",
    "    Returns\n",
    "    -------\n",
    "    result : Combined Pi for the FHMM\n",
    "    \"\"\"\n",
    "    result = list_pi[0]\n",
    "    for i in range(len(list_pi) - 1):\n",
    "        result = np.kron(result, list_pi[i + 1])\n",
    "    return result\n",
    "\n",
    "def combine_means(means_list):\n",
    "    \"\"\"\n",
    "    Compute factorized model states means\n",
    "    :param means_list: list of individual models' state means\n",
    "    :return: column vector of fatorized state means\n",
    "    \"\"\"\n",
    "    states_combination = list(itertools.product(*means_list))\n",
    "    num_combinations = len(states_combination)\n",
    "    means_stacked = np.array([sum(x) for x in states_combination])\n",
    "    means = np.reshape(means_stacked, (num_combinations, 1))\n",
    "    cov = np.tile(5 * np.identity(1), (num_combinations, 1, 1))\n",
    "    return [means, cov]\n",
    "\n",
    "def sort_startprob(mapping, startprob):\n",
    "    \"\"\" Sort the startprob according to power means; as returned by mapping\n",
    "    \"\"\"\n",
    "    num_elements = len(startprob)\n",
    "    new_startprob = np.zeros(num_elements)\n",
    "    for i in xrange(len(startprob)):\n",
    "        new_startprob[i] = startprob[mapping[i]]\n",
    "    return new_startprob\n",
    "\n",
    "\n",
    "def sort_covars(mapping, covars):\n",
    "    new_covars = np.zeros_like(covars)\n",
    "    for i in xrange(len(covars)):\n",
    "        new_covars[i] = covars[mapping[i]]\n",
    "    return new_covars\n",
    "\n",
    "\n",
    "def sort_transition_matrix(mapping, A):\n",
    "    \"\"\"Sorts the transition matrix according to increasing order of\n",
    "    power means; as returned by mapping\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapping :\n",
    "    A : numpy.array of shape (k, k)\n",
    "        transition matrix\n",
    "    \"\"\"\n",
    "    num_elements = len(A)\n",
    "    A_new = np.zeros((num_elements, num_elements))\n",
    "    for i in range(num_elements):\n",
    "        for j in range(num_elements):\n",
    "            A_new[i, j] = A[mapping[i], mapping[j]]\n",
    "    return A_new\n",
    "\n",
    "\n",
    "def sort_learnt_parameters(startprob, means, covars, transmat):\n",
    "    mapping = return_sorting_mapping(means)\n",
    "    means_new = np.sort(means, axis=0)\n",
    "    startprob_new = sort_startprob(mapping, startprob)\n",
    "    covars_new = sort_covars(mapping, covars)\n",
    "    transmat_new = sort_transition_matrix(mapping, transmat)\n",
    "    assert np.shape(means_new) == np.shape(means)\n",
    "    assert np.shape(startprob_new) == np.shape(startprob)\n",
    "    assert np.shape(transmat_new) == np.shape(transmat)\n",
    "\n",
    "    return [startprob_new, means_new, covars_new, transmat_new]\n",
    "\n",
    "\n",
    "def return_sorting_mapping(means):\n",
    "    means_copy = deepcopy(means)\n",
    "    means_copy = np.sort(means_copy, axis=0)\n",
    "\n",
    "    # Finding mapping\n",
    "    mapping = {}\n",
    "    for i, val in enumerate(means_copy):\n",
    "        mapping[i] = np.where(val == means)[0][0]\n",
    "    return mapping\n",
    "\n",
    "def create_combined_hmm(model):\n",
    "    list_pi = [model[appliance].startprob_ for appliance in model]\n",
    "    list_A = [model[appliance].transmat_ for appliance in model]\n",
    "    list_means = [model[appliance].means_.flatten().tolist()\n",
    "                  for appliance in model]\n",
    "\n",
    "    pi_combined = compute_pi_fhmm(list_pi)\n",
    "    A_combined = compute_A_fhmm(list_A)\n",
    "    [mean_combined, cov_combined] = combine_means(list_means)\n",
    "\n",
    "    combined_model = GaussianHMM(\n",
    "        n_components=len(pi_combined), covariance_type='full',\n",
    "        startprob_prior=pi_combined, transmat_prior=A_combined)\n",
    "    combined_model.covars_ = cov_combined\n",
    "    combined_model.means_ = mean_combined\n",
    "    combined_model.startprob_ = pi_combined\n",
    "    combined_model.transmat_ = A_combined\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "def decode_hmm(length_sequence, centroids, appliance_list, states):\n",
    "    \"\"\"\n",
    "    Decodes the HMM state sequence\n",
    "    \"\"\"\n",
    "    hmm_states = {}\n",
    "    hmm_power = {}\n",
    "    total_num_combinations = 1\n",
    "\n",
    "    for appliance in appliance_list:\n",
    "        total_num_combinations *= len(centroids[appliance])\n",
    "\n",
    "    for appliance in appliance_list:\n",
    "        hmm_states[appliance] = np.zeros(length_sequence, dtype=np.int)\n",
    "        hmm_power[appliance] = np.zeros(length_sequence)\n",
    "\n",
    "    for i in range(length_sequence):\n",
    "\n",
    "        factor = total_num_combinations\n",
    "        for appliance in appliance_list:\n",
    "            # assuming integer division (will cause errors in Python 3x)\n",
    "            factor = factor // len(centroids[appliance])\n",
    "\n",
    "            temp = int(states[i]) / factor\n",
    "            hmm_states[appliance][i] = temp % len(centroids[appliance])\n",
    "            hmm_power[appliance][i] = centroids[appliance][hmm_states[appliance][i]]\n",
    "    return [hmm_states, hmm_power]\n",
    "\n",
    "class FHMM():\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : dict\n",
    "    predictions : pd.DataFrame()\n",
    "    meters : list\n",
    "    MIN_CHUNK_LENGTH : int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.predictions = pd.DataFrame()\n",
    "        self.MIN_CHUNK_LENGTH = 100\n",
    "        self.MODEL_NAME = 'FHMM'\n",
    "\n",
    "\n",
    "    def train(self, appliances, num_states_dict={}, **load_kwargs):\n",
    "        \"\"\"Train using 1d FHMM.\n",
    "        Places the learnt model in `model` attribute\n",
    "        The current version performs training ONLY on the first chunk.\n",
    "        Online HMMs are welcome if someone can contribute :)\n",
    "        Assumes all pre-processing has been done.\n",
    "        \"\"\"\n",
    "        learnt_model = OrderedDict()\n",
    "        num_meters = len(appliances)\n",
    "        if num_meters > 12:\n",
    "            max_num_clusters = 2\n",
    "        else:\n",
    "            max_num_clusters = 3\n",
    "\n",
    "        for i, app in enumerate(appliances):\n",
    "            power_data = app.power_data.fillna(value = 0,inplace = False)\n",
    "            X = power_data.values.reshape((-1, 1))\n",
    "            assert X.ndim == 2\n",
    "            self.X = X\n",
    "\n",
    "            if num_states_dict.get(app.name) is not None:\n",
    "                # User has specified the number of states for this appliance\n",
    "                num_total_states = num_states_dict.get(app.name)\n",
    "\n",
    "            else:\n",
    "                # Find the optimum number of states\n",
    "                print \"Identifying number of hidden states for appliance {}\".format(app.name)\n",
    "                states = cluster(X, max_num_clusters)\n",
    "                num_total_states = len(states)\n",
    "                print \"Number of hidden states for appliance {}: {}\".format(app.name, num_total_states)\n",
    "\n",
    "            print(\"Training model for appliance {} with {} hidden states\".format(app.name, num_total_states))\n",
    "            learnt_model[app.name] = GaussianHMM(num_total_states, \"full\")\n",
    "\n",
    "            # Fit\n",
    "            learnt_model[app.name].fit(X)\n",
    "\n",
    "\n",
    "        # Combining to make a AFHMM\n",
    "        self.meters = []\n",
    "        new_learnt_models = OrderedDict()\n",
    "        for app in learnt_model:\n",
    "            startprob, means, covars, transmat = sort_learnt_parameters(\n",
    "                learnt_model[app].startprob_, learnt_model[app].means_,\n",
    "                learnt_model[app].covars_, learnt_model[app].transmat_)\n",
    "            new_learnt_models[app] = GaussianHMM(\n",
    "                startprob.size, \"full\")\n",
    "            new_learnt_models[app].means_ = means\n",
    "            new_learnt_models[app].covars_ = covars\n",
    "            new_learnt_models[app].startprob_ = startprob\n",
    "            new_learnt_models[app].transmat_ = transmat\n",
    "            # UGLY! But works.\n",
    "            self.meters.append(app)\n",
    "\n",
    "        learnt_model_combined = create_combined_hmm(new_learnt_models)\n",
    "        self.individual = new_learnt_models\n",
    "        self.model = learnt_model_combined\n",
    "\n",
    "    def disaggregate_chunk(self, test_mains):\n",
    "        \"\"\"Disaggregate the test data according to the model learnt previously\n",
    "        Performs 1D FHMM disaggregation.\n",
    "        For now assuming there is no missing data at this stage.\n",
    "        :param test_mains: test dataframe with aggregate data\n",
    "        \"\"\"\n",
    "\n",
    "        # Array of learnt states\n",
    "        learnt_states_array = []\n",
    "        test_mains = test_mains.dropna()\n",
    "        length = len(test_mains.index)\n",
    "        temp = test_mains.values.reshape(length, 1)\n",
    "        learnt_states_array.append(self.model.predict(temp))\n",
    "\n",
    "        # Model\n",
    "        means = OrderedDict()\n",
    "        for elec_meter, model in self.individual.iteritems():\n",
    "            means[elec_meter] = (\n",
    "                model.means_.round().astype(int).flatten().tolist())\n",
    "            means[elec_meter].sort()\n",
    "\n",
    "        decoded_power_array = []\n",
    "        decoded_states_array = []\n",
    "\n",
    "        for learnt_states in learnt_states_array:\n",
    "            [decoded_states, decoded_power] = decode_hmm(\n",
    "                len(learnt_states), means, means.keys(), learnt_states)\n",
    "            decoded_states_array.append(decoded_states)\n",
    "            decoded_power_array.append(decoded_power)\n",
    "\n",
    "        prediction = pd.DataFrame(\n",
    "            decoded_power_array[0], index=test_mains.index)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def disaggregate(self, mains, output_datastore, sample_period = 20):\n",
    "        '''Disaggregate mains according to the model learnt previously.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mains : dataframe with aggregated output\n",
    "        output_datastore : instance of nilmtk.DataStore subclass\n",
    "            For storing power predictions from disaggregation algorithm.\n",
    "        sample_period : number, optional\n",
    "            The desired sample period in minutes.\n",
    "        **load_kwargs : key word arguments\n",
    "            Passed to `mains.power_series(**kwargs)`\n",
    "        '''\n",
    "        for g, chunk in mains.groupby(np.arange(len(mains)) // sample_period):\n",
    "            predictions = self.disaggregate_chunk(chunk)\n",
    "            output_datastore = output_datastore.append(predictions)\n",
    "            if g != 0 and g%72 == 0:\n",
    "                print \"Disaggregated {} day(s) of data\".format(g/72)\n",
    "        return output_datastore\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "class Appliance():\n",
    "    def __init__(self, name, power_data):\n",
    "        self.name =  name\n",
    "        self.power_data = power_data\n",
    "        self.good_chunks = power_data[(power_data[name]>1)]\n",
    "\n",
    "def train_test_split(dataframe, split, second_split = None):\n",
    "    '''\n",
    "    Splits dataframe into training and validation set\n",
    "    :param dataframe: total dataframe\n",
    "    :param split: date on which to split\n",
    "    :param second_split: option to create second test set\n",
    "    :return: train, test and optionally second test dataframe\n",
    "    '''\n",
    "    df = dataframe.fillna(value = 0,inplace = False)\n",
    "    df['total'] = dataframe.sum(axis = 1)\n",
    "    if second_split:\n",
    "        return df[:split], df[split:second_split], df[second_split:]\n",
    "    else:\n",
    "        return df[:split], df[split:]\n",
    "\n",
    "def create_matrix(appliance,good_chunks = True):\n",
    "    if not good_chunks:\n",
    "        power_data = appliance.power_data\n",
    "    else:\n",
    "        power_data = appliance.good_chunks\n",
    "    return power_data.values.reshape((-1, 1))\n",
    "\n",
    "def cluster(x_train,x_test, max_number_clusters):\n",
    "    \"\"\"\n",
    "    Iteratevely finds an optimal number of clusters based on silhouette score\n",
    "    :param data: N*K numpy array, in case of a 1D array supply a column vector N*1\n",
    "    :param max_number_clusters: integer, highest number of clusters\n",
    "    :return: cluster centers\n",
    "    \"\"\"\n",
    "    highest_score = -1\n",
    "    for i in xrange(2,max_number_clusters):\n",
    "        print \"Fitting a KMeans model with {} clusters\".format(i)\n",
    "        kmeans = KMeans(n_clusters = i, n_jobs = -1).fit(x_train)\n",
    "        labels = kmeans.predict(x_test)\n",
    "        print \"Calculating silhouette score...\"\n",
    "        s_score = silhouette_score(x_test, labels, sample_size = 10000)\n",
    "        if s_score > highest_score:\n",
    "            highest_score = s_score\n",
    "            centers = kmeans.cluster_centers_\n",
    "        print \"Silhouette score with {} clusters:{}\".format(i,s_score)\n",
    "    print \"Highest silhouete score of {} achieved with {} clusters\\n\".format(highest_score,len(centers))\n",
    "    return centers\n",
    "\n",
    "def Create_combined_states(df):\n",
    "    new_df = df.copy()\n",
    "    columns = new_df.columns\n",
    "    column_combinations = []\n",
    "    for i in xrange(2,len(columns)+1):\n",
    "        column_combinations = column_combinations + list(itertools.combinations(columns,i))\n",
    "\n",
    "    for x in column_combinations:\n",
    "        name = \" \".join(list(x))\n",
    "        new_df[name] = df[list(x)].sum(axis = 1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
