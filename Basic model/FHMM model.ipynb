{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from FHMM import FHMM\n",
    "#from HMM import HMM, HMM_MAD, perc_std_expl,r2\n",
    "#from Preprocessing import Create_combined_states, Appliance, train_test_split,create_matrix\n",
    "import math\n",
    "\n",
    "\n",
    "##could define R functions after getting predictionsea\n",
    "def perc_std_expl_full(pred_df,obs_df):\n",
    "    \"\"\"\n",
    "    :param observed: df of observed energy levels per channel\n",
    "    :param predicted: df of predicted energy levels per channel\n",
    "    :return: percentage of standard deviation explained\n",
    "    \"\"\"\n",
    "    return_dict = {}\n",
    "    for channel in pred_df:\n",
    "        X_pred = pred_df[[channel]].values\n",
    "        X_obs = obs_df[[channel]].values\n",
    "        obs_mean = np.mean(X_obs)\n",
    "        r2 = 1 - (np.sum((X_obs - X_pred)**2))/np.sum((X_obs - obs_mean)**2)\n",
    "        return_dict[channel] = 1 - math.sqrt(1-r2)\n",
    "    return return_dict\n",
    "\n",
    "def r2_full(pred_df,obs_df):\n",
    "    return_dict = {}\n",
    "    for channel in pred_df:\n",
    "        X_pred = pred_df[[channel]].values\n",
    "        X_obs = obs_df[[channel]].values\n",
    "        obs_mean = np.mean(X_obs)\n",
    "        r2 = 1 - (np.sum((X_obs - X_pred)**2))/np.sum((X_obs - obs_mean)**2)\n",
    "        return_dict[channel] = r2\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "\n",
    "class Appliance():\n",
    "    def __init__(self, name, power_data):\n",
    "        self.name=name\n",
    "        self.power_data = power_data\n",
    "        self.good_chunks = power_data[(power_data[name]>1)]\n",
    "        \n",
    "        \n",
    "\n",
    "def create_matrix(appliance, good_chunks = True):\n",
    "    if not good_chunks:\n",
    "        power_data = appliance.power_data\n",
    "    else:\n",
    "        power_data = appliance.good_chunks\n",
    "    \n",
    "    return power_data.values.reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HMM.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm, pyplot as plt\n",
    "from matplotlib.dates import YearLocator, MonthLocator\n",
    "import cPickle as pk\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import math\n",
    "\n",
    "def HMM_MAD(model,obs_levels):\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    abs_error = np.absolute(obs_levels - predict_levels)\n",
    "    return np.mean(abs_error)/np.mean(obs_levels)\n",
    "\n",
    "def perc_std_expl(model,obs_levels):\n",
    "    \"\"\"\n",
    "    :param observed: df of observed energy levels per channel\n",
    "    :param predicted: df of predicted energy levels per channel\n",
    "    :return: percentage of standard deviation explained\n",
    "    \"\"\"\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    obs_mean = np.mean(obs_levels)\n",
    "    r2 = 1 - (np.sum((obs_levels - predict_levels)**2))/np.sum((obs_levels - obs_mean)**2)\n",
    "    return 1 - math.sqrt(1-r2)\n",
    "\n",
    "def r2(model,obs_levels):\n",
    "    hidden_states = model.predict(obs_levels)\n",
    "    means = model.means_.round().astype(int).flatten().tolist()\n",
    "    predict_levels = np.array([means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "    obs_mean = np.mean(obs_levels)\n",
    "    r2 = 1 - (np.sum((obs_levels - predict_levels)**2))/np.sum((obs_levels - obs_mean)**2)\n",
    "    return r2\n",
    "\n",
    "class HMM():\n",
    "    def __init__(self, X_test, X_train):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.n_states = None\n",
    "        self.model =  None\n",
    "\n",
    "    def fit_HMM(self,error_metric):\n",
    "        print \"Looking for optimal number of states and fitting HMM\"\n",
    "        for i in xrange(2,5):\n",
    "            candidate = GaussianHMM(n_components=i, covariance_type=\"full\", n_iter=1000)\n",
    "            candidate.fit(self.X_train)\n",
    "            if error_metric == HMM_MAD:\n",
    "                error = HMM_MAD(candidate,self.X_test)\n",
    "                if i == 2:\n",
    "                    best_guess = error\n",
    "                    best_model = candidate\n",
    "                    opt_n_states = i\n",
    "                else:\n",
    "                    if error < best_guess:\n",
    "                        opt_n_states = i\n",
    "                        best_model = candidate\n",
    "                        best_guess = error\n",
    "            else:\n",
    "                error = error_metric(candidate,self.X_test)\n",
    "                if i == 2:\n",
    "                    best_guess = error\n",
    "                    best_model = candidate\n",
    "                    opt_n_states = i\n",
    "                else:\n",
    "                    if error > best_guess:\n",
    "                        opt_n_states = i\n",
    "                        best_model = candidate\n",
    "                        best_guess = error\n",
    "        self.model = best_model\n",
    "        self.n_states = opt_n_states\n",
    "        print \"Done. Lowest error of {} achieved with {} states\".format(best_guess, opt_n_states)\n",
    "\n",
    "    def extract_means(self):\n",
    "        return self.model.means_[:,0].flatten()\n",
    "\n",
    "    def HMM_total_accuracy(self, obs_levels, state_means):\n",
    "        hidden_states = self.model.predict(obs_levels)\n",
    "        predict_levels = [state_means[state] for state in hidden_states]\n",
    "        test_error = 1 - (np.sum(obs_levels[:,0]) - np.sum(predict_levels))/np.sum(obs_levels[:,0])\n",
    "        return test_error\n",
    "\n",
    "    def HMM_MAD_perc(self,obs_levels, state_means):\n",
    "        hidden_states = self.model.predict(obs_levels)\n",
    "        predict_levels = np.array([state_means[state] for state in hidden_states]).reshape(obs_levels.shape)\n",
    "        abs_error = np.absolute(obs_levels - predict_levels)\n",
    "        return np.mean(abs_error)/np.mean(obs_levels)\n",
    "\n",
    "    def run(self):\n",
    "        self.fit_HMM()\n",
    "        state_means = self.extract_means()\n",
    "        test_error = self.HMM_accuracy(self.X_test, state_means)\n",
    "        print \"Accuracy for the model with {} hidden states is: {}\".format(self.n_states,test_error)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FHMM.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from Preprocessing import cluster\n",
    "\n",
    "def compute_A_fhmm(list_A):\n",
    "    result = list_A[0]\n",
    "    for i in range(len(list_A) - 1):\n",
    "        result = np.kron(result, list_A[i + 1])\n",
    "    return result\n",
    "\n",
    "def combine_parameters(ind_parameters_list):\n",
    "    '''\n",
    "    Function to compute factorized HMM parameters such as starting probabilities or transition matrices\n",
    "    from individual model parameters\n",
    "    :param ind_parameters_list: parameter list for individual models (per appliance), e.g. list of starting probabilites,\n",
    "    transition matrices\n",
    "    :return: matrix of factorized model parameters\n",
    "    '''\n",
    "    FactAParam = ind_parameters_list[0]\n",
    "    for idx in xrange(1,len(ind_parameters_list)):\n",
    "        FactA = np.kron(FactAParam,ind_parameters_list[idx])\n",
    "    return FactAParam\n",
    "\n",
    "def compute_pi_fhmm(list_pi):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    list_pi : List of PI's of individual learnt HMMs\n",
    "    Returns\n",
    "    -------\n",
    "    result : Combined Pi for the FHMM\n",
    "    \"\"\"\n",
    "    result = list_pi[0]\n",
    "    for i in range(len(list_pi) - 1):\n",
    "        result = np.kron(result, list_pi[i + 1])\n",
    "    return result\n",
    "\n",
    "def combine_means(means_list):\n",
    "    \"\"\"\n",
    "    Compute factorized model states means\n",
    "    :param means_list: list of individual models' state means\n",
    "    :return: column vector of fatorized state means\n",
    "    \"\"\"\n",
    "    states_combination = list(itertools.product(*means_list))\n",
    "    num_combinations = len(states_combination)\n",
    "    means_stacked = np.array([sum(x) for x in states_combination])\n",
    "    means = np.reshape(means_stacked, (num_combinations, 1))\n",
    "    cov = np.tile(5 * np.identity(1), (num_combinations, 1, 1))\n",
    "    return [means, cov]\n",
    "\n",
    "def sort_startprob(mapping, startprob):\n",
    "    \"\"\" Sort the startprob according to power means; as returned by mapping\n",
    "    \"\"\"\n",
    "    num_elements = len(startprob)\n",
    "    new_startprob = np.zeros(num_elements)\n",
    "    for i in xrange(len(startprob)):\n",
    "        new_startprob[i] = startprob[mapping[i]]\n",
    "    return new_startprob\n",
    "\n",
    "\n",
    "def sort_covars(mapping, covars):\n",
    "    new_covars = np.zeros_like(covars)\n",
    "    for i in xrange(len(covars)):\n",
    "        new_covars[i] = covars[mapping[i]]\n",
    "    return new_covars\n",
    "\n",
    "\n",
    "def sort_transition_matrix(mapping, A):\n",
    "    \"\"\"Sorts the transition matrix according to increasing order of\n",
    "    power means; as returned by mapping\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapping :\n",
    "    A : numpy.array of shape (k, k)\n",
    "        transition matrix\n",
    "    \"\"\"\n",
    "    num_elements = len(A)\n",
    "    A_new = np.zeros((num_elements, num_elements))\n",
    "    for i in range(num_elements):\n",
    "        for j in range(num_elements):\n",
    "            A_new[i, j] = A[mapping[i], mapping[j]]\n",
    "    return A_new\n",
    "\n",
    "\n",
    "def sort_learnt_parameters(startprob, means, covars, transmat):\n",
    "    mapping = return_sorting_mapping(means)\n",
    "    means_new = np.sort(means, axis=0)\n",
    "    startprob_new = sort_startprob(mapping, startprob)\n",
    "    covars_new = sort_covars(mapping, covars)\n",
    "    transmat_new = sort_transition_matrix(mapping, transmat)\n",
    "    assert np.shape(means_new) == np.shape(means)\n",
    "    assert np.shape(startprob_new) == np.shape(startprob)\n",
    "    assert np.shape(transmat_new) == np.shape(transmat)\n",
    "\n",
    "    return [startprob_new, means_new, covars_new, transmat_new]\n",
    "\n",
    "\n",
    "def return_sorting_mapping(means):\n",
    "    means_copy = deepcopy(means)\n",
    "    means_copy = np.sort(means_copy, axis=0)\n",
    "\n",
    "    # Finding mapping\n",
    "    mapping = {}\n",
    "    for i, val in enumerate(means_copy):\n",
    "        mapping[i] = np.where(val == means)[0][0]\n",
    "    return mapping\n",
    "\n",
    "def create_combined_hmm(model):\n",
    "    list_pi = [model[appliance].startprob_ for appliance in model]\n",
    "    list_A = [model[appliance].transmat_ for appliance in model]\n",
    "    list_means = [model[appliance].means_.flatten().tolist()\n",
    "                  for appliance in model]\n",
    "\n",
    "    pi_combined = compute_pi_fhmm(list_pi)\n",
    "    A_combined = compute_A_fhmm(list_A)\n",
    "    [mean_combined, cov_combined] = combine_means(list_means)\n",
    "\n",
    "    combined_model = GaussianHMM(\n",
    "        n_components=len(pi_combined), covariance_type='full',\n",
    "        startprob_prior=pi_combined, transmat_prior=A_combined)\n",
    "    combined_model.covars_ = cov_combined\n",
    "    combined_model.means_ = mean_combined\n",
    "    combined_model.startprob_ = pi_combined\n",
    "    combined_model.transmat_ = A_combined\n",
    "    return combined_model\n",
    "\n",
    "\n",
    "def decode_hmm(length_sequence, centroids, appliance_list, states):\n",
    "    \"\"\"\n",
    "    Decodes the HMM state sequence\n",
    "    \"\"\"\n",
    "    hmm_states = {}\n",
    "    hmm_power = {}\n",
    "    total_num_combinations = 1\n",
    "\n",
    "    for appliance in appliance_list:\n",
    "        total_num_combinations *= len(centroids[appliance])\n",
    "\n",
    "    for appliance in appliance_list:\n",
    "        hmm_states[appliance] = np.zeros(length_sequence, dtype=np.int)\n",
    "        hmm_power[appliance] = np.zeros(length_sequence)\n",
    "\n",
    "    for i in range(length_sequence):\n",
    "\n",
    "        factor = total_num_combinations\n",
    "        for appliance in appliance_list:\n",
    "            # assuming integer division (will cause errors in Python 3x)\n",
    "            factor = factor // len(centroids[appliance])\n",
    "\n",
    "            temp = int(states[i]) / factor\n",
    "            hmm_states[appliance][i] = temp % len(centroids[appliance])\n",
    "            hmm_power[appliance][i] = centroids[appliance][hmm_states[appliance][i]]\n",
    "    return [hmm_states, hmm_power]\n",
    "\n",
    "class FHMM():\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : dict\n",
    "    predictions : pd.DataFrame()\n",
    "    meters : list\n",
    "    MIN_CHUNK_LENGTH : int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.predictions = pd.DataFrame()\n",
    "        self.MIN_CHUNK_LENGTH = 100\n",
    "        self.MODEL_NAME = 'FHMM'\n",
    "\n",
    "\n",
    "    def train(self, appliances, num_states_dict={}, **load_kwargs):\n",
    "        \"\"\"Train using 1d FHMM.\n",
    "        Places the learnt model in `model` attribute\n",
    "        The current version performs training ONLY on the first chunk.\n",
    "        Online HMMs are welcome if someone can contribute :)\n",
    "        Assumes all pre-processing has been done.\n",
    "        \"\"\"\n",
    "        learnt_model = OrderedDict()\n",
    "        num_meters = len(appliances)\n",
    "        if num_meters > 12:\n",
    "            max_num_clusters = 2\n",
    "        else:\n",
    "            max_num_clusters = 3\n",
    "\n",
    "        for i, app in enumerate(appliances):\n",
    "            power_data = app.power_data.fillna(value = 0,inplace = False)\n",
    "            X = power_data.values.reshape((-1, 1))\n",
    "            assert X.ndim == 2\n",
    "            self.X = X\n",
    "\n",
    "            if num_states_dict.get(app.name) is not None:\n",
    "                # User has specified the number of states for this appliance\n",
    "                num_total_states = num_states_dict.get(app.name)\n",
    "\n",
    "            else:\n",
    "                # Find the optimum number of states\n",
    "                print \"Identifying number of hidden states for appliance {}\".format(app.name)\n",
    "                states = cluster(X, max_num_clusters)\n",
    "                num_total_states = len(states)\n",
    "                print \"Number of hidden states for appliance {}: {}\".format(app.name, num_total_states)\n",
    "\n",
    "            print(\"Training model for appliance {} with {} hidden states\".format(app.name, num_total_states))\n",
    "            learnt_model[app.name] = GaussianHMM(num_total_states, \"full\")\n",
    "\n",
    "            # Fit\n",
    "            learnt_model[app.name].fit(X)\n",
    "\n",
    "\n",
    "        # Combining to make a AFHMM\n",
    "        self.meters = []\n",
    "        new_learnt_models = OrderedDict()\n",
    "        for app in learnt_model:\n",
    "            startprob, means, covars, transmat = sort_learnt_parameters(\n",
    "                learnt_model[app].startprob_, learnt_model[app].means_,\n",
    "                learnt_model[app].covars_, learnt_model[app].transmat_)\n",
    "            new_learnt_models[app] = GaussianHMM(\n",
    "                startprob.size, \"full\")\n",
    "            new_learnt_models[app].means_ = means\n",
    "            new_learnt_models[app].covars_ = covars\n",
    "            new_learnt_models[app].startprob_ = startprob\n",
    "            new_learnt_models[app].transmat_ = transmat\n",
    "            # UGLY! But works.\n",
    "            self.meters.append(app)\n",
    "\n",
    "        learnt_model_combined = create_combined_hmm(new_learnt_models)\n",
    "        self.individual = new_learnt_models\n",
    "        self.model = learnt_model_combined\n",
    "\n",
    "    def disaggregate_chunk(self, test_mains):\n",
    "        \"\"\"Disaggregate the test data according to the model learnt previously\n",
    "        Performs 1D FHMM disaggregation.\n",
    "        For now assuming there is no missing data at this stage.\n",
    "        :param test_mains: test dataframe with aggregate data\n",
    "        \"\"\"\n",
    "\n",
    "        # Array of learnt states\n",
    "        learnt_states_array = []\n",
    "        test_mains = test_mains.dropna()\n",
    "        length = len(test_mains.index)\n",
    "        temp = test_mains.values.reshape(length, 1)\n",
    "        learnt_states_array.append(self.model.predict(temp))\n",
    "\n",
    "        # Model\n",
    "        means = OrderedDict()\n",
    "        for elec_meter, model in self.individual.iteritems():\n",
    "            means[elec_meter] = (\n",
    "                model.means_.round().astype(int).flatten().tolist())\n",
    "            means[elec_meter].sort()\n",
    "\n",
    "        decoded_power_array = []\n",
    "        decoded_states_array = []\n",
    "\n",
    "        for learnt_states in learnt_states_array:\n",
    "            [decoded_states, decoded_power] = decode_hmm(\n",
    "                len(learnt_states), means, means.keys(), learnt_states)\n",
    "            decoded_states_array.append(decoded_states)\n",
    "            decoded_power_array.append(decoded_power)\n",
    "\n",
    "        prediction = pd.DataFrame(\n",
    "            decoded_power_array[0], index=test_mains.index)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def disaggregate(self, mains, output_datastore, sample_period = 20):\n",
    "        '''Disaggregate mains according to the model learnt previously.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mains : dataframe with aggregated output\n",
    "        output_datastore : instance of nilmtk.DataStore subclass\n",
    "            For storing power predictions from disaggregation algorithm.\n",
    "        sample_period : number, optional\n",
    "            The desired sample period in minutes.\n",
    "        **load_kwargs : key word arguments\n",
    "            Passed to `mains.power_series(**kwargs)`\n",
    "        '''\n",
    "        for g, chunk in mains.groupby(np.arange(len(mains)) // sample_period):\n",
    "            predictions = self.disaggregate_chunk(chunk)\n",
    "            output_datastore = output_datastore.append(predictions)\n",
    "            if g != 0 and g%72 == 0:\n",
    "                print \"Disaggregated {} day(s) of data\".format(g/72)\n",
    "        return output_datastore\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  air conditioner1  air conditioner2  washing machine  \\\n",
      "0      7/13/2013 0:01               0.0               0.0              0.0   \n",
      "1      7/14/2013 0:01               0.0               0.0              0.0   \n",
      "2      7/15/2013 0:01               0.0               0.0              0.0   \n",
      "3      7/16/2013 0:01               0.0               0.0              0.0   \n",
      "4      7/17/2013 0:01               0.0               0.0              0.0   \n",
      "5      7/18/2013 0:01               0.0               0.0              0.0   \n",
      "6      7/19/2013 0:01               0.0               0.0              0.0   \n",
      "7      7/20/2013 0:01               0.0               0.0              0.0   \n",
      "8      7/21/2013 0:01               0.0               0.0              0.0   \n",
      "9      7/22/2013 0:01               0.0               0.0              0.0   \n",
      "10     7/23/2013 0:01               0.0               0.0              0.0   \n",
      "11     7/24/2013 0:01               0.0               0.0              0.0   \n",
      "12     7/25/2013 0:01               0.0               0.0              0.0   \n",
      "13     7/26/2013 0:01               0.0               0.0              0.0   \n",
      "14     7/27/2013 0:01               0.0               0.0              0.0   \n",
      "15     7/28/2013 0:01               0.0               0.0              0.0   \n",
      "16     7/29/2013 0:01               0.0               0.0              0.0   \n",
      "17     7/30/2013 0:01               0.0               0.0              0.0   \n",
      "18     7/31/2013 0:01               0.0               0.0              0.0   \n",
      "19      8/1/2013 0:01               0.0               0.0              0.0   \n",
      "20      8/2/2013 0:01               0.0               0.0              0.0   \n",
      "21      8/3/2013 0:01               0.0               0.0              0.0   \n",
      "22      8/4/2013 0:01               0.0               0.0              0.0   \n",
      "23      8/5/2013 0:01               0.0               0.0              0.0   \n",
      "24      8/6/2013 0:01               0.0               0.0              0.0   \n",
      "25      8/7/2013 0:01               0.0               0.0              0.0   \n",
      "26      8/8/2013 0:01               0.0               0.0              0.0   \n",
      "27      8/9/2013 0:01               0.0               0.0              0.0   \n",
      "28     8/10/2013 0:01               0.0               0.0              0.0   \n",
      "29     8/11/2013 0:01               0.0               0.0              0.0   \n",
      "...               ...               ...               ...              ...   \n",
      "33089  2/16/2104 0:01               0.0               0.0              0.0   \n",
      "33090  2/17/2104 0:01               0.0               0.0              0.0   \n",
      "33091  2/18/2104 0:01               0.0               0.0              0.0   \n",
      "33092  2/19/2104 0:01               0.0               0.0              0.0   \n",
      "33093  2/20/2104 0:01               0.0               0.0              0.0   \n",
      "33094  2/21/2104 0:01               0.0               0.0              0.0   \n",
      "33095  2/22/2104 0:01               0.0               0.0              0.0   \n",
      "33096  2/23/2104 0:01               0.0               0.0              0.0   \n",
      "33097  2/24/2104 0:01               0.0               0.0              0.0   \n",
      "33098  2/25/2104 0:01               0.0               0.0              0.0   \n",
      "33099  2/26/2104 0:01               0.0               0.0              0.0   \n",
      "33100  2/27/2104 0:01               0.0               0.0              0.0   \n",
      "33101  2/28/2104 0:01               0.0               0.0              0.0   \n",
      "33102  2/29/2104 0:01               0.0               0.0              0.0   \n",
      "33103   3/1/2104 0:01               0.0               0.0              0.0   \n",
      "33104   3/2/2104 0:01               0.0               0.0              0.0   \n",
      "33105   3/3/2104 0:01               0.0               0.0              0.0   \n",
      "33106   3/4/2104 0:01               0.0               0.0              0.0   \n",
      "33107   3/5/2104 0:01               0.0               0.0              0.0   \n",
      "33108   3/6/2104 0:01               0.0               0.0              0.0   \n",
      "33109   3/7/2104 0:01               0.0               0.0              0.0   \n",
      "33110   3/8/2104 0:01               0.0               0.0              0.0   \n",
      "33111   3/9/2104 0:01               0.0               0.0              0.0   \n",
      "33112  3/10/2104 0:01               0.0               0.0              0.0   \n",
      "33113  3/11/2104 0:01               0.0               0.0              0.0   \n",
      "33114  3/12/2104 0:01               0.0               0.0              0.0   \n",
      "33115  3/13/2104 0:01               0.0               0.0              0.0   \n",
      "33116  3/14/2104 0:01               0.0               0.0              0.0   \n",
      "33117  3/15/2104 0:01               0.0               0.0              0.0   \n",
      "33118  3/16/2104 0:01               0.0               0.0              0.0   \n",
      "\n",
      "       laptop computer  television      total  \n",
      "0            41.796533   75.667040  41.796533  \n",
      "1            36.988000   73.835085  36.988000  \n",
      "2            35.709483   75.075672  35.709483  \n",
      "3            34.634390   73.159068  34.634390  \n",
      "4            33.628467   73.572203  33.628467  \n",
      "5            33.271667   70.163118  33.271667  \n",
      "6            33.644638   74.244848  33.644638  \n",
      "7            30.391833    0.000000  30.391833  \n",
      "8            32.257729    0.000000  32.257729  \n",
      "9            30.982576    0.000000  30.982576  \n",
      "10           30.503017    0.000000  30.503017  \n",
      "11           27.881271    0.000000  27.881271  \n",
      "12           28.904133    0.000000  28.904133  \n",
      "13           27.618877    0.000000  27.618877  \n",
      "14           27.590517    0.000000  27.590517  \n",
      "15           27.312644    0.000000  27.312644  \n",
      "16           27.340754    0.000000  27.340754  \n",
      "17           24.535949    0.000000  24.535949  \n",
      "18           21.900983    0.000000  21.900983  \n",
      "19           21.494254    0.000000  21.494254  \n",
      "20           21.554475    0.000000  21.554475  \n",
      "21           21.732424    0.000000  21.732424  \n",
      "22           21.973850    0.000000  21.973850  \n",
      "23           21.663649    0.000000  21.663649  \n",
      "24           21.516500    0.000000  21.516500  \n",
      "25           21.963932    0.000000  21.963932  \n",
      "26           21.339050    0.000000  21.339050  \n",
      "27           21.919000    0.000000  21.919000  \n",
      "28           21.434867    0.000000  21.434867  \n",
      "29           21.672932    0.000000  21.672932  \n",
      "...                ...         ...        ...  \n",
      "33089        59.912917    0.000000  59.912917  \n",
      "33090        62.543400    0.000000  62.543400  \n",
      "33091        62.303339    0.000000  62.303339  \n",
      "33092        61.406850    0.000000  61.406850  \n",
      "33093        60.830483    0.000000  60.830483  \n",
      "33094        60.864367    0.000000  60.864367  \n",
      "33095        61.059356    0.000000  61.059356  \n",
      "33096        61.127083    0.000000  61.127083  \n",
      "33097        61.241167    0.000000  61.241167  \n",
      "33098        61.414085    0.000000  61.414085  \n",
      "33099        61.446867    0.000000  61.446867  \n",
      "33100        61.495783    0.000000  61.495783  \n",
      "33101        61.689200    0.000000  61.689200  \n",
      "33102        62.393966    0.000000  62.393966  \n",
      "33103        63.243917    0.000000  63.243917  \n",
      "33104        64.969345    0.000000  64.969345  \n",
      "33105        65.058053    0.000000  65.058053  \n",
      "33106        64.744667    0.000000  64.744667  \n",
      "33107        64.240000    0.000000  64.240000  \n",
      "33108        67.692133    0.000000  67.692133  \n",
      "33109        68.054390    0.000000  68.054390  \n",
      "33110        67.477517    0.000000  67.477517  \n",
      "33111        69.466633    0.000000  69.466633  \n",
      "33112        63.338750    0.000000  63.338750  \n",
      "33113        60.485350    0.000000  60.485350  \n",
      "33114        57.151117    0.000000  57.151117  \n",
      "33115        54.993517    0.000000  54.993517  \n",
      "33116        53.889867    0.000000  53.889867  \n",
      "33117        51.581867    0.000000  51.581867  \n",
      "33118        49.145433    0.000000  49.145433  \n",
      "\n",
      "[33119 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/yli/Desktop/energy disaggregation/Basic model/formated.iawe.data/short.df.0713-0804.csv') as f:\n",
    "    combined = pd.read_csv(f)\n",
    "combined.shape\n",
    "type(combined)    \n",
    "\n",
    "print combined\n",
    "#combined = total['2013-06-01 00:00:00': '2013-09-30 23:59:59'][['channel_12','channel_5','channel_6','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'air conditioner1', u'air conditioner2', u'washing machine',\n",
       "       u'laptop computer', u'television'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  air conditioner1  air conditioner2  washing machine  \\\n",
      "0      7/29/2013 0:00               0.0               0.0              0.0   \n",
      "1      7/29/2013 0:01               0.0               0.0              0.0   \n",
      "2      7/29/2013 0:02               0.0               0.0              0.0   \n",
      "3      7/29/2013 0:03               0.0               0.0              0.0   \n",
      "4      7/29/2013 0:04               0.0               0.0              0.0   \n",
      "5      7/29/2013 0:05               0.0               0.0              0.0   \n",
      "6      7/29/2013 0:06               0.0               0.0              0.0   \n",
      "7      7/29/2013 0:07               0.0               0.0              0.0   \n",
      "8      7/29/2013 0:08               0.0               0.0              0.0   \n",
      "9      7/29/2013 0:09               0.0               0.0              0.0   \n",
      "10     7/29/2013 0:10               0.0               0.0              0.0   \n",
      "11     7/29/2013 0:11               0.0               0.0              0.0   \n",
      "12     7/29/2013 0:12               0.0               0.0              0.0   \n",
      "13     7/29/2013 0:13               0.0               0.0              0.0   \n",
      "14     7/29/2013 0:14               0.0               0.0              0.0   \n",
      "15     7/29/2013 0:15               0.0               0.0              0.0   \n",
      "16     7/29/2013 0:16               0.0               0.0              0.0   \n",
      "17     7/29/2013 0:17               0.0               0.0              0.0   \n",
      "18     7/29/2013 0:18               0.0               0.0              0.0   \n",
      "19     7/29/2013 0:19               0.0               0.0              0.0   \n",
      "20     7/29/2013 0:20               0.0               0.0              0.0   \n",
      "21     7/29/2013 0:21               0.0               0.0              0.0   \n",
      "22     7/29/2013 0:22               0.0               0.0              0.0   \n",
      "23     7/29/2013 0:23               0.0               0.0              0.0   \n",
      "24     7/29/2013 0:24               0.0               0.0              0.0   \n",
      "25     7/29/2013 0:25               0.0               0.0              0.0   \n",
      "26     7/29/2013 0:26               0.0               0.0              0.0   \n",
      "27     7/29/2013 0:27               0.0               0.0              0.0   \n",
      "28     7/29/2013 0:28               0.0               0.0              0.0   \n",
      "29     7/29/2013 0:29               0.0               0.0              0.0   \n",
      "...               ...               ...               ...              ...   \n",
      "10050  8/4/2013 23:30               0.0               0.0              0.0   \n",
      "10051  8/4/2013 23:31               0.0               0.0              0.0   \n",
      "10052  8/4/2013 23:32               0.0               0.0              0.0   \n",
      "10053  8/4/2013 23:33               0.0               0.0              0.0   \n",
      "10054  8/4/2013 23:34               0.0               0.0              0.0   \n",
      "10055  8/4/2013 23:35               0.0               0.0              0.0   \n",
      "10056  8/4/2013 23:36               0.0               0.0              0.0   \n",
      "10057  8/4/2013 23:37               0.0               0.0              0.0   \n",
      "10058  8/4/2013 23:38               0.0               0.0              0.0   \n",
      "10059  8/4/2013 23:39               0.0               0.0              0.0   \n",
      "10060  8/4/2013 23:40               0.0               0.0              0.0   \n",
      "10061  8/4/2013 23:41               0.0               0.0              0.0   \n",
      "10062  8/4/2013 23:42               0.0               0.0              0.0   \n",
      "10063  8/4/2013 23:43               0.0               0.0              0.0   \n",
      "10064  8/4/2013 23:44               0.0               0.0              0.0   \n",
      "10065  8/4/2013 23:45               0.0               0.0              0.0   \n",
      "10066  8/4/2013 23:46               0.0               0.0              0.0   \n",
      "10067  8/4/2013 23:47               0.0               0.0              0.0   \n",
      "10068  8/4/2013 23:48               0.0               0.0              0.0   \n",
      "10069  8/4/2013 23:49               0.0               0.0              0.0   \n",
      "10070  8/4/2013 23:50               0.0               0.0              0.0   \n",
      "10071  8/4/2013 23:51               0.0               0.0              0.0   \n",
      "10072  8/4/2013 23:52               0.0               0.0              0.0   \n",
      "10073  8/4/2013 23:53               0.0               0.0              0.0   \n",
      "10074  8/4/2013 23:54               0.0               0.0              0.0   \n",
      "10075  8/4/2013 23:55               0.0               0.0              0.0   \n",
      "10076  8/4/2013 23:56               0.0               0.0              0.0   \n",
      "10077  8/4/2013 23:57               0.0               0.0              0.0   \n",
      "10078  8/4/2013 23:58               0.0               0.0              0.0   \n",
      "10079  8/4/2013 23:59               0.0               0.0              0.0   \n",
      "\n",
      "       laptop computer  television      total  \n",
      "0             0.000000         0.0   0.000000  \n",
      "1             0.000000         0.0   0.000000  \n",
      "2             0.000000         0.0   0.000000  \n",
      "3             0.000000         0.0   0.000000  \n",
      "4             0.000000         0.0   0.000000  \n",
      "5             0.000000         0.0   0.000000  \n",
      "6             0.000000         0.0   0.000000  \n",
      "7             0.000000         0.0   0.000000  \n",
      "8             0.000000         0.0   0.000000  \n",
      "9             0.000000         0.0   0.000000  \n",
      "10            0.000000         0.0   0.000000  \n",
      "11            0.000000         0.0   0.000000  \n",
      "12            0.000000         0.0   0.000000  \n",
      "13            0.000000         0.0   0.000000  \n",
      "14            0.000000         0.0   0.000000  \n",
      "15            0.000000         0.0   0.000000  \n",
      "16            0.000000         0.0   0.000000  \n",
      "17            0.000000         0.0   0.000000  \n",
      "18            0.000000         0.0   0.000000  \n",
      "19            0.000000         0.0   0.000000  \n",
      "20            0.000000         0.0   0.000000  \n",
      "21            0.000000         0.0   0.000000  \n",
      "22            0.000000         0.0   0.000000  \n",
      "23            0.000000         0.0   0.000000  \n",
      "24            0.000000         0.0   0.000000  \n",
      "25            0.000000         0.0   0.000000  \n",
      "26            0.000000         0.0   0.000000  \n",
      "27            0.000000         0.0   0.000000  \n",
      "28            0.000000         0.0   0.000000  \n",
      "29            0.000000         0.0   0.000000  \n",
      "...                ...         ...        ...  \n",
      "10050        59.912917         0.0  59.912917  \n",
      "10051        62.543400         0.0  62.543400  \n",
      "10052        62.303339         0.0  62.303339  \n",
      "10053        61.406850         0.0  61.406850  \n",
      "10054        60.830483         0.0  60.830483  \n",
      "10055        60.864367         0.0  60.864367  \n",
      "10056        61.059356         0.0  61.059356  \n",
      "10057        61.127083         0.0  61.127083  \n",
      "10058        61.241167         0.0  61.241167  \n",
      "10059        61.414085         0.0  61.414085  \n",
      "10060        61.446867         0.0  61.446867  \n",
      "10061        61.495783         0.0  61.495783  \n",
      "10062        61.689200         0.0  61.689200  \n",
      "10063        62.393966         0.0  62.393966  \n",
      "10064        63.243917         0.0  63.243917  \n",
      "10065        64.969345         0.0  64.969345  \n",
      "10066        65.058053         0.0  65.058053  \n",
      "10067        64.744667         0.0  64.744667  \n",
      "10068        64.240000         0.0  64.240000  \n",
      "10069        67.692133         0.0  67.692133  \n",
      "10070        68.054390         0.0  68.054390  \n",
      "10071        67.477517         0.0  67.477517  \n",
      "10072        69.466633         0.0  69.466633  \n",
      "10073        63.338750         0.0  63.338750  \n",
      "10074        60.485350         0.0  60.485350  \n",
      "10075        57.151117         0.0  57.151117  \n",
      "10076        54.993517         0.0  54.993517  \n",
      "10077        53.889867         0.0  53.889867  \n",
      "10078        51.581867         0.0  51.581867  \n",
      "10079        49.145433         0.0  49.145433  \n",
      "\n",
      "[10080 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/yli/Desktop/energy disaggregation/Basic model/formated.iawe.data/train.csv') as f:\n",
    "    train_set = pd.read_csv(f)\n",
    "    \n",
    "with open('C:/Users/yli/Desktop/energy disaggregation/Basic model/formated.iawe.data/test.csv') as f:\n",
    "    test_set = pd.read_csv(f)\n",
    "#print train_set[['air conditioner1']]\n",
    "#print test_set[['television']]\n",
    "print test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       air conditioner1\n",
      "656         1075.787875\n",
      "657          395.366217\n",
      "658          396.637569\n",
      "659          765.930067\n",
      "660         1677.935483\n",
      "661         1782.302158\n",
      "662         1826.711900\n",
      "663         1850.200250\n",
      "664         1860.634707\n",
      "665         1859.967475\n",
      "666         1865.927500\n",
      "667         1853.444617\n",
      "668         1857.175411\n",
      "669         1866.131150\n",
      "670         1872.481717\n",
      "671         1865.324322\n",
      "672         1867.373783\n",
      "673         1865.090883\n",
      "674         1874.780729\n",
      "675         1855.380424\n",
      "676         1866.622300\n",
      "677         1868.850550\n",
      "678         1867.524482\n",
      "679         1868.010617\n",
      "680         1868.792167\n",
      "681         1871.168034\n",
      "682         1865.011649\n",
      "683         1867.568158\n",
      "684         1859.206704\n",
      "685         1872.053186\n",
      "...                 ...\n",
      "22357       1744.744200\n",
      "22358       1751.196035\n",
      "22359       1740.503600\n",
      "22360       1730.134983\n",
      "22361       1725.536068\n",
      "22362       1720.706733\n",
      "22363       1716.701200\n",
      "22364       1719.058450\n",
      "22365       1725.723018\n",
      "22366       1717.797067\n",
      "22367       1708.230733\n",
      "22368       1703.488051\n",
      "22369       1711.228250\n",
      "22370       1719.473017\n",
      "22371       1717.891643\n",
      "22372       1704.761400\n",
      "22373       1704.702717\n",
      "22374       1700.129621\n",
      "22375       1708.409431\n",
      "22376       1701.272067\n",
      "22377       1697.590733\n",
      "22378       1701.657298\n",
      "22379       1697.760867\n",
      "22380       1692.132517\n",
      "22381       1693.880271\n",
      "22382       1693.148800\n",
      "22383       1713.235633\n",
      "22384       1723.590847\n",
      "22385       1718.645911\n",
      "22386       1724.025039\n",
      "\n",
      "[1631 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "app_train_list = []\n",
    "app_test_list = []\n",
    "\n",
    "print Appliance('air conditioner1',train_set[['air conditioner1']]).good_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'time', u'air conditioner1', u'air conditioner2', u'washing machine',\n",
      "       u'laptop computer', u'television', u'total'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Appliance instance at 0x000000000C83BEC8>, <__main__.Appliance instance at 0x000000000C6B94C8>, <__main__.Appliance instance at 0x000000000C6B9BC8>, <__main__.Appliance instance at 0x000000000C587D88>, <__main__.Appliance instance at 0x000000000C587E48>]\n"
     ]
    }
   ],
   "source": [
    "for app in combined.columns[1:-1]:\n",
    "    app_train_list.append(Appliance(app,train_set[[app]]))\n",
    "    app_test_list.append(Appliance(app,test_set[[app]]))\n",
    "    \n",
    "num_states_dict = {}\n",
    "ModelDict = {}\n",
    "\n",
    "print app_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air conditioner1\n",
      "Looking for optimal number of states and fitting HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Lowest error of 0.393882874677 achieved with 3 states\n",
      "air conditioner2\n",
      "Looking for optimal number of states and fitting HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Lowest error of 0.689481900608 achieved with 4 states\n",
      "washing machine\n",
      "Looking for optimal number of states and fitting HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Lowest error of -0.00026724660246 achieved with 3 states\n",
      "laptop computer\n",
      "Looking for optimal number of states and fitting HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Lowest error of 0.307184865107 achieved with 3 states\n",
      "television\n",
      "Looking for optimal number of states and fitting HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Lowest error of -0.188231805586 achieved with 4 states\n"
     ]
    }
   ],
   "source": [
    "for i, app in enumerate(app_train_list):\n",
    "    X_train = create_matrix(app,good_chunks = True)\n",
    "    X_test = create_matrix(app_test_list[i], good_chunks = False)\n",
    "    hmm = HMM(X_train, X_test)\n",
    "    print app.name\n",
    "    hmm.fit_HMM(perc_std_expl)\n",
    "    ModelDict[app.name] = hmm.model\n",
    "    num_states_dict[app.name] = hmm.n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for appliance air conditioner1 with 3 hidden states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for appliance air conditioner2 with 4 hidden states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for appliance washing machine with 3 hidden states\n",
      "Training model for appliance laptop computer with 3 hidden states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for appliance television with 4 hidden states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaggregated 1 day(s) of data\n",
      "Disaggregated 2 day(s) of data\n",
      "Disaggregated 3 day(s) of data\n",
      "Disaggregated 4 day(s) of data\n",
      "Disaggregated 5 day(s) of data\n",
      "Disaggregated 6 day(s) of data\n"
     ]
    }
   ],
   "source": [
    "fhmm = FHMM()\n",
    "fhmm.train(app_train_list,num_states_dict = num_states_dict)\n",
    "predictions = pd.DataFrame()\n",
    "predictions = fhmm.disaggregate(test_set[['total']],predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_power_predicted = predictions.sum()\n",
    "total_power_act = test_set[predictions.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent stand.dev.explained, 1min: {'air conditioner2': 0.225808701926014, 'laptop computer': 0.18158541309225207, 'television': 0.058370127659651105, 'air conditioner1': 0.42364010258867413, 'washing machine': -2.1976209834096925}\n",
      "R2, 1min: {'air conditioner2': 0.40062783398651647, 'laptop computer': 0.33019756393662036, 'television': 0.11333318351629829, 'air conditioner1': 0.66780926865600587, 'washing machine': -9.2247799535419688}\n"
     ]
    }
   ],
   "source": [
    "print \"Percent stand.dev.explained, 1min:\", perc_std_expl_full(predictions, test_set)\n",
    "print \"R2, 1min:\", r2_full(predictions, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_15Min = predictions.resample(\"15Min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air conditioner1    1158960.0\n",
      "air conditioner2    1180554.0\n",
      "laptop computer      139390.0\n",
      "television           185883.0\n",
      "washing machine      113192.0\n",
      "dtype: float64\n",
      "air conditioner1    1.628854e+06\n",
      "air conditioner2    8.781208e+05\n",
      "laptop computer     1.269026e+05\n",
      "television          1.089918e+05\n",
      "washing machine     1.483415e+04\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print total_power_predicted\n",
    "print total_power_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       air conditioner1  air conditioner2  laptop computer  television  \\\n",
      "0                   0.0               0.0             25.0        72.0   \n",
      "1                   0.0               0.0              0.0         0.0   \n",
      "2                   0.0               0.0              0.0         0.0   \n",
      "3                   0.0               0.0              0.0         0.0   \n",
      "4                   0.0               0.0              0.0         0.0   \n",
      "5                   0.0               0.0              0.0         0.0   \n",
      "6                   0.0               0.0              0.0         0.0   \n",
      "7                   0.0               0.0              0.0         0.0   \n",
      "8                   0.0               0.0              0.0         0.0   \n",
      "9                   0.0               0.0              0.0         0.0   \n",
      "10                  0.0               0.0              0.0         0.0   \n",
      "11                  0.0               0.0              0.0         0.0   \n",
      "12                  0.0               0.0              0.0         0.0   \n",
      "13                  0.0               0.0              0.0         0.0   \n",
      "14                  0.0               0.0              0.0         0.0   \n",
      "15                  0.0               0.0              0.0         0.0   \n",
      "16                  0.0               0.0              0.0         0.0   \n",
      "17                  0.0               0.0              0.0         0.0   \n",
      "18                  0.0               0.0              0.0         0.0   \n",
      "19                  0.0               0.0              0.0         0.0   \n",
      "20                  0.0               0.0             25.0        72.0   \n",
      "21                  0.0               0.0              0.0         0.0   \n",
      "22                  0.0               0.0              0.0         0.0   \n",
      "23                  0.0               0.0              0.0         0.0   \n",
      "24                  0.0               0.0              0.0         0.0   \n",
      "25                  0.0               0.0              0.0         0.0   \n",
      "26                  0.0               0.0              0.0         0.0   \n",
      "27                  0.0               0.0              0.0         0.0   \n",
      "28                  0.0               0.0              0.0         0.0   \n",
      "29                  0.0               0.0              0.0         0.0   \n",
      "...                 ...               ...              ...         ...   \n",
      "10050               0.0               0.0             55.0         0.0   \n",
      "10051               0.0               0.0             55.0         0.0   \n",
      "10052               0.0               0.0             55.0         0.0   \n",
      "10053               0.0               0.0             55.0         0.0   \n",
      "10054               0.0               0.0             55.0         0.0   \n",
      "10055               0.0               0.0             55.0         0.0   \n",
      "10056               0.0               0.0             55.0         0.0   \n",
      "10057               0.0               0.0             55.0         0.0   \n",
      "10058               0.0               0.0             55.0         0.0   \n",
      "10059               0.0               0.0             55.0         0.0   \n",
      "10060               0.0               0.0             25.0        72.0   \n",
      "10061               0.0               0.0             55.0         0.0   \n",
      "10062               0.0               0.0             55.0         0.0   \n",
      "10063               0.0               0.0             55.0         0.0   \n",
      "10064               0.0               0.0             55.0         0.0   \n",
      "10065               0.0               0.0              0.0        72.0   \n",
      "10066               0.0               0.0              0.0        72.0   \n",
      "10067               0.0               0.0              0.0        72.0   \n",
      "10068               0.0               0.0              0.0        72.0   \n",
      "10069               0.0               0.0              0.0        72.0   \n",
      "10070               0.0               0.0              0.0        72.0   \n",
      "10071               0.0               0.0              0.0        72.0   \n",
      "10072               0.0               0.0              0.0        72.0   \n",
      "10073               0.0               0.0             55.0         0.0   \n",
      "10074               0.0               0.0             55.0         0.0   \n",
      "10075               0.0               0.0             55.0         0.0   \n",
      "10076               0.0               0.0             55.0         0.0   \n",
      "10077               0.0               0.0             55.0         0.0   \n",
      "10078               0.0               0.0             55.0         0.0   \n",
      "10079               0.0               0.0             55.0         0.0   \n",
      "\n",
      "       washing machine  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "5                  0.0  \n",
      "6                  0.0  \n",
      "7                  0.0  \n",
      "8                  0.0  \n",
      "9                  0.0  \n",
      "10                 0.0  \n",
      "11                 0.0  \n",
      "12                 0.0  \n",
      "13                 0.0  \n",
      "14                 0.0  \n",
      "15                 0.0  \n",
      "16                 0.0  \n",
      "17                 0.0  \n",
      "18                 0.0  \n",
      "19                 0.0  \n",
      "20                 0.0  \n",
      "21                 0.0  \n",
      "22                 0.0  \n",
      "23                 0.0  \n",
      "24                 0.0  \n",
      "25                 0.0  \n",
      "26                 0.0  \n",
      "27                 0.0  \n",
      "28                 0.0  \n",
      "29                 0.0  \n",
      "...                ...  \n",
      "10050              0.0  \n",
      "10051              0.0  \n",
      "10052              0.0  \n",
      "10053              0.0  \n",
      "10054              0.0  \n",
      "10055              0.0  \n",
      "10056              0.0  \n",
      "10057              0.0  \n",
      "10058              0.0  \n",
      "10059              0.0  \n",
      "10060              0.0  \n",
      "10061              0.0  \n",
      "10062              0.0  \n",
      "10063              0.0  \n",
      "10064              0.0  \n",
      "10065              0.0  \n",
      "10066              0.0  \n",
      "10067              0.0  \n",
      "10068              0.0  \n",
      "10069              0.0  \n",
      "10070              0.0  \n",
      "10071              0.0  \n",
      "10072              0.0  \n",
      "10073              0.0  \n",
      "10074              0.0  \n",
      "10075              0.0  \n",
      "10076              0.0  \n",
      "10077              0.0  \n",
      "10078              0.0  \n",
      "10079              0.0  \n",
      "\n",
      "[10080 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out predictions dataframe\n",
    "\n",
    "predictions.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-621bfdd6f13c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmin15_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"15Min\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mresample\u001b[1;34m(self, rule, how, axis, fill_method, closed, label, convention, kind, loffset, limit, base, on, level)\u001b[0m\n\u001b[0;32m   7102\u001b[0m                      \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloffset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7103\u001b[0m                      \u001b[0mconvention\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvention\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7104\u001b[1;33m                      base=base, key=on, level=level)\n\u001b[0m\u001b[0;32m   7105\u001b[0m         return _maybe_process_deprecations(r,\n\u001b[0;32m   7106\u001b[0m                                            \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\resample.pyc\u001b[0m in \u001b[0;36mresample\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;34m\"\"\" create a TimeGrouper and return our resampler \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mtg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeGrouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\resample.pyc\u001b[0m in \u001b[0;36m_get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   1274\u001b[0m         raise TypeError(\"Only valid with DatetimeIndex, \"\n\u001b[0;32m   1275\u001b[0m                         \u001b[1;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                         \"but got an instance of %r\" % type(ax).__name__)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_grouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
